{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actividad de perceptrón y perceptrón multicapa\n",
    "#### Autor: Francisco Serradilla\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Escribir el código de propagación y actualización de pesos del perceptrón. [Done]\n",
    "- Escribir el código de propagación y actualización de pesos del perceptrón multicapa para una capa oculta.[Done]\n",
    "- Encontrar arquitecturas mínimas para el problema no lineal y el problema de clasificación de orquídeas. [Done]\n",
    "- Ampliar el código del perceptrón Multicapa para calcular el error de test a partir de otro conjunto de datos.\n",
    "- Probar entrenamiento y cálculo del error de test con el juego de datos de aprobados.\n",
    "- (hacer al menos dos) Probar con problemas adicionales (circulo, aprobados, fun, morosos). Al final hay una explicación de los conjuntos de datos suministrados.\n",
    "- (opcional) Añadir una segunda capa oculta al perceptrón multacapa y/o un múmero indefinido de capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, ninput, noutput):\n",
    "        self.ninput = ninput\n",
    "        self.noutput = noutput\n",
    "        self.w = np.random.rand(ninput,noutput)-0.5\n",
    "        self.b = np.random.rand(noutput)-0.5\n",
    "        \n",
    "    def forward (self, x): # propaga un vector x y devuelve la salida\n",
    "        # a implementar\n",
    "        #np.matmul() multiplica matrices\n",
    "        neta = np.matmul(x,self.w) + self.b;\n",
    "        return np.piecewise(neta, [neta < 0, neta >= 0], [0, 1]) #funcion escalon\n",
    "    \n",
    "    def update (self, x, d, alpha): # realiza una iteración de entrenamiento\n",
    "        s = self.forward(x) # propaga\n",
    "        etranspose = x.reshape(-1,1) #trasponer el vector (todos sus elementos con -1) a 1 columna\n",
    "        AW = alpha*etranspose*(d-s)\n",
    "        self.w = self.w + AW\n",
    "        \n",
    "    def RMS (self, X, D):\n",
    "        S = self.forward(X)\n",
    "        return np.mean(np.sqrt(np.mean(np.square(S-D),axis=1)))\n",
    "        \n",
    "    def accuracy (self, X, D):\n",
    "        S = self.forward(X)\n",
    "        errors = np.mean(np.abs(D-S))\n",
    "        return 1.0 - errors\n",
    "    \n",
    "    def info (self, X, D):\n",
    "        print('     RMS: %6.5f' % self.RMS(X,D))\n",
    "        print('Accuracy: %6.5f' % self.accuracy(X,D))\n",
    "        \n",
    "    def train (self, X, D, alpha, epochs, trace=0):\n",
    "        for e in range(1,epochs+1):\n",
    "            for i in range(len(X)):\n",
    "                self.update(X[i],D[i], alpha)\n",
    "            if trace!=0 and e%trace == 0:\n",
    "                print('\\n   Epoch: %d' % e)\n",
    "                self.info(X,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     RMS: 0.75000\n",
      "Accuracy: 0.25000\n",
      "\n",
      "   Epoch: 10\n",
      "     RMS: 0.75000\n",
      "Accuracy: 0.25000\n",
      "\n",
      "   Epoch: 20\n",
      "     RMS: 0.25000\n",
      "Accuracy: 0.75000\n",
      "\n",
      "   Epoch: 30\n",
      "     RMS: 0.00000\n",
      "Accuracy: 1.00000\n",
      "\n",
      "   Epoch: 40\n",
      "     RMS: 0.00000\n",
      "Accuracy: 1.00000\n",
      "\n",
      "   Epoch: 50\n",
      "     RMS: 0.00000\n",
      "Accuracy: 1.00000\n"
     ]
    }
   ],
   "source": [
    "# entrena para la OR\n",
    "\n",
    "p = Perceptron(2,1)\n",
    "\n",
    "# or\n",
    "data = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "labels = np.array([[0.0], [1.0], [1.0], [1.0]])\n",
    "\n",
    "p.info(data, labels)\n",
    "p.train(data, labels, 0.01, 50, 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holi Perceptrón multi capa para una capa oculta \n",
    "class Multilayer:\n",
    "    def __init__(self, ninput, nhidden, noutput):\n",
    "        self.ninput = ninput\n",
    "        self.nhidden = nhidden\n",
    "        self.noutput = noutput\n",
    "\n",
    "        self.w1 = np.random.rand(ninput,nhidden)-0.5\n",
    "        self.b1 = np.random.rand(nhidden)-0.5\n",
    "        self.w2 = np.random.rand(nhidden,noutput)-0.5\n",
    "        self.b2 = np.random.rand(noutput)-0.5\n",
    "        \n",
    "        self.sx = []\n",
    "        \n",
    "        self.lRMS = [] # contiene la lista de RMSs para pintarlos\n",
    "        self.laccuracy = [] # contiene la lista de accuracy\n",
    "\n",
    "    def sigm (self, neta):\n",
    "        return 1.0 / (1.0 + np.exp(-neta))\n",
    "    \n",
    "    def forward (self, x): # propaga un vector x y devuelve la salida\n",
    "        self.sx = []\n",
    "        # Propagación \n",
    "        # Capa 1\n",
    "        #sx.append(self.forward(x))     # Salida para la propagación de la capa 1\n",
    "        netax = np.matmul(x,self.w1) + self.b1;\n",
    "        self.sx.append(self.sigm(netax)) # sk = Fs(s(k-1)*Wk+bk)\n",
    "        \n",
    "        # Capa 2\n",
    "        #sx.append(self.forward(sx[0])) # Salida para la propagación de la capa 2\n",
    "        netax = np.matmul(self.sx[0],self.w2) + self.b2;\n",
    "        self.sx.append(self.sigm(netax)) # sk = Fs(s(k-1)*Wk+bk)\n",
    "        return self.sx[-1]\n",
    "    \n",
    "    def update (self, x, d, alpha): # realiza una iteración de entrenamiento\n",
    "        # a implementar\n",
    "        AW = []    # delta pesos   inicia de la capa final y termina en la inicial  F-->I\n",
    "        Ab = []    # delta bias    inicia de la capa final y termina en la inicial  F-->I\n",
    "        delta = [] # Deltas error  inicia de la capa final y termina en la inicial  F-->I\n",
    "        #sx = []    # Salidas inicia en la capa inicial y termina en la final  I-->F\n",
    "        \n",
    "        self.forward(x)\n",
    "        # Retropropagar \n",
    "        # Capa final (capa 2)\n",
    "        # Error de la capa final \n",
    "        delta.append((d-self.sx[1])*self.sx[1]*([1]-self.sx[1])) # Error para la capa final (capa 2)\n",
    "\n",
    "        # Modificar pesos para la capa final\n",
    "        s1tras = self.sx[0].reshape(-1,1) #trasponer\n",
    "      \n",
    "        \n",
    "        AW.append(alpha * s1tras * delta[0]) # dif pesos\n",
    "        Ab.append(alpha * delta[0]) # dif bias\n",
    "        \n",
    "        # Primera capa (capa 1)\n",
    "        # Error de la primera capa (capa 1)\n",
    "        W2tras = self.w2.transpose() ## creo que este era el error \n",
    "        fderivada = self.sx[0] * ([1] - self.sx[0])\n",
    "        \n",
    "        delta.append(np.matmul(delta[0], W2tras)*fderivada)\n",
    "        \n",
    "        # Modificar pesos para la primera capa\n",
    "        s0tras = x.reshape(-1,1) #trasponer\n",
    "        AW.append(alpha * s0tras * delta[1]) # dif pesos\n",
    "        Ab.append(alpha * delta[1]) # dif bias\n",
    "        \n",
    "        #actualizar pesos y bias\n",
    "        # Capa 2 \n",
    "        self.w2 = self.w2 + AW[0]\n",
    "        self.b2 = self.b2 + Ab[0]\n",
    "        \n",
    "        # Capa 1 \n",
    "        self.w1 = self.w1 + AW[1]\n",
    "        self.b1 = self.b1 + Ab[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def RMS (self, X, D):\n",
    "        S = self.forward(X)\n",
    "        return np.mean(np.sqrt(np.mean(np.square(S-D),axis=1)))\n",
    "        \n",
    "    def accuracy (self, X, D):\n",
    "        S = self.forward(X)\n",
    "        S = np.round(S)\n",
    "        errors = np.mean(np.abs(D-S))\n",
    "        return 1.0 - errors\n",
    "    \n",
    "    def info (self, X, D):\n",
    "        self.lRMS.append(self.RMS(X,D))\n",
    "        self.laccuracy.append(self.accuracy(X,D))\n",
    "        print('     RMS: %6.5f' % self.lRMS[-1])\n",
    "        print('Accuracy: %6.5f' % self.laccuracy[-1])\n",
    "        \n",
    "    def train (self, X, D, alpha, epochs, trace=0):\n",
    "        self.lRMS = [] # guarda lista de RMSs para pintarlos\n",
    "        self.laccuracy = [] # guarda lista de accuracy\n",
    "\n",
    "        for e in range(1,epochs+1):\n",
    "            for i in range(len(X)):\n",
    "                self.update(X[i],D[i], alpha)\n",
    "            if trace!=0 and e%trace == 0:\n",
    "                print('\\n   Epoch: %d' % e)\n",
    "                self.info(X,D)\n",
    "    def test (self, X, D, alpha, epochs, trace=0): \n",
    "        self.lRMS = [] # guarda lista de RMSs para pintarlos\n",
    "        self.laccuracy = [] # guarda lista de accuracy\n",
    "\n",
    "        for e in range(1,epochs+1):\n",
    "            if trace!=0 and e%trace == 0:\n",
    "                print('\\n   Epoch: %d' % e)\n",
    "                self.info(X,D)\n",
    "                \n",
    "def one_hot (d):\n",
    "    num_classes = len(set(d))\n",
    "    rows = d.shape[0]\n",
    "    labels = np.zeros((rows, num_classes), dtype='float32')\n",
    "    labels[np.arange(rows),d.T] = 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     RMS: 0.49999\n",
      "Accuracy: 0.50000\n",
      "\n",
      "   Epoch: 1000\n",
      "     RMS: 0.07436\n",
      "Accuracy: 1.00000\n",
      "\n",
      "   Epoch: 2000\n",
      "     RMS: 0.03374\n",
      "Accuracy: 1.00000\n",
      "\n",
      "   Epoch: 3000\n",
      "     RMS: 0.02479\n",
      "Accuracy: 1.00000\n",
      "\n",
      "   Epoch: 4000\n",
      "     RMS: 0.02042\n",
      "Accuracy: 1.00000\n",
      "\n",
      "   Epoch: 5000\n",
      "     RMS: 0.01774\n",
      "Accuracy: 1.00000\n"
     ]
    }
   ],
   "source": [
    "# xor\n",
    "data = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "labels = np.array([[0.0], [1.0], [1.0], [0.0]])\n",
    "\n",
    "p = Multilayer(2,2,1)\n",
    "\n",
    "p.info(data, labels)\n",
    "p.train(data, labels, 1, 5000, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Epoch: 1\n",
      "     RMS: 0.02000\n",
      "Accuracy: 0.98000\n",
      "\n",
      "   Epoch: 2\n",
      "     RMS: 0.01000\n",
      "Accuracy: 0.99000\n",
      "\n",
      "   Epoch: 3\n",
      "     RMS: 0.01000\n",
      "Accuracy: 0.99000\n",
      "\n",
      "   Epoch: 4\n",
      "     RMS: 0.01000\n",
      "Accuracy: 0.99000\n",
      "\n",
      "   Epoch: 5\n",
      "     RMS: 0.01000\n",
      "Accuracy: 0.99000\n",
      "\n",
      "   Epoch: 6\n",
      "     RMS: 0.01000\n",
      "Accuracy: 0.99000\n",
      "\n",
      "   Epoch: 7\n",
      "     RMS: 0.01000\n",
      "Accuracy: 0.99000\n",
      "\n",
      "   Epoch: 8\n",
      "     RMS: 0.01000\n",
      "Accuracy: 0.99000\n",
      "\n",
      "   Epoch: 9\n",
      "     RMS: 0.01000\n",
      "Accuracy: 0.99000\n",
      "\n",
      "   Epoch: 10\n",
      "     RMS: 0.01000\n",
      "Accuracy: 0.99000\n"
     ]
    }
   ],
   "source": [
    "# example data from two classes; 2D normal distributions\n",
    "num = 100\n",
    "x0 = np.random.multivariate_normal([2,2], np.array([[1,0],[0,1]]),num)\n",
    "d0 = np.repeat(0, num)\n",
    "x1 = np.random.multivariate_normal([-2,-2], np.array([[1,0],[0,1]]),num)\n",
    "d1 = np.repeat(1, num)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlim(-6,6)\n",
    "plt.ylim(-6,6)\n",
    "plt.plot(x0[:,0],x0[:,1],'o')\n",
    "plt.plot(x1[:,0],x1[:,1],'o')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "X = np.vstack((x0,x1))\n",
    "d = np.hstack((d0,d1))\n",
    "d.shape = (200,1) # convierte el vector en un array\n",
    "\n",
    "p = Perceptron(2,1)\n",
    "\n",
    "p.train(X, d, 0.01, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# regiones no lineales\n",
    "\n",
    "X = np.loadtxt('samples/data_3classes_nonlinear_2D.txt')\n",
    "\n",
    "d = X[:,-1].astype('int')\n",
    "X = X[:,:-1]\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.plot(X[d==0,0],X[d==0,1], 'ro')\n",
    "plt.plot(X[d==1,0],X[d==1,1], 'go')\n",
    "plt.plot(X[d==2,0],X[d==2,1], 'bo')\n",
    "plt.show()\n",
    "\n",
    "no = len(set(d))\n",
    "ni = X.shape[1]\n",
    "\n",
    "d = one_hot(d)\n",
    "\n",
    "p = Multilayer(ni,15,no)\n",
    "\n",
    "# encontrar arquitectura mínima que aprende este problema, para data_2classes_nonlinear_2D.txt y para data_3classes_nonlinear_2D.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orquideas\n",
    "\n",
    "X = np.loadtxt('samples\\iris.csv', dtype = 'float64', usecols = [0,1,2,3])\n",
    "L = np.loadtxt('samples\\iris.csv', dtype = str, usecols = [4]) \n",
    "\n",
    "# convierte la salida a enteros\n",
    "d = []\n",
    "options = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "for e in L:\n",
    "    d.append(options.index(e))\n",
    "\n",
    "d = np.array(d)\n",
    "X = np.array(X)\n",
    "\n",
    "d = one_hot(d)\n",
    "\n",
    "ni = X.shape[1]\n",
    "no = len(options)\n",
    "\n",
    "p = Multilayer(ni,40,no)\n",
    "\n",
    "# encontrar arquitectura mínima que aprende este problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicación de los archivos de datos suministrados\n",
    "\n",
    "#### Aprobados\n",
    "\n",
    "Contiene 3 entradas, correspondiente a la nota en 3 ejercicios, y 1 salida, que indica si el alumno aprobó o no. Se trataría de predecir si un alumno va a aprobar a partir de sus notas. Es un problema de clasificación.\n",
    "\n",
    "Cuestiones: ¿Es un problema lineal? ¿Puede aprenderla una red de neuronas?\n",
    "\n",
    "#### Fun\n",
    "\n",
    "Contiene 1 entrada y 1 salida, que son la *x* y la *y* de una función desconocida. Es un problema de ajuste o regresión.\n",
    "\n",
    "Cuestiones: ¿Es una función lineal? ¿Puede aprenderla una red de neuronas? ¿Puede decirnos la red qué función es?\n",
    "\n",
    "#### Morosos\n",
    "\n",
    "Contiene datos de morosidad de un banco. La idea es predecir si un nuevo cliente va a devolver un prestamo o no y utilizar esta predicción para concederle o denegarle el préstamo. Es un problema de clasificación.\n",
    "\n",
    "Tiene 9 entradas y 1 salida.\n",
    "\n",
    "Cuestiones: ¿Es una función lineal? ¿Cuál es el porcentaje de acierto estimado en test?\n",
    "\n",
    "#### Quinielas\n",
    "\n",
    "Contiene datos de quinielas deportivas. Tiene 60 entradas y 3 salidas (1, X, 2). Es un problema de clasificación.\n",
    "\n",
    "Cuestiones: ¿Cuál es el porcentaje de acierto estimado en test?\n",
    "\n",
    "#### Sensores\n",
    "\n",
    "Contiene datos de sensores y velocidades medias en la M-40. La idea es ver si se puede predecir la velocidad media en un punto que no tiene sensor a partir de las lecturas de los sensores en otros puntos. Es un problema de ajuste o regresión.\n",
    "\n",
    "Cuestiones: ¿Cuál es el porcentaje de acierto estimado en test?\n",
    "\n",
    "#### Circulo\n",
    "\n",
    "Es un problema de clasificación con 3 regiones concéntricas. No tiene conjunto de test, el objetivo es encontrar la red mínima que pueda clasificar correctamente todos los ejemplos.\n",
    "\n",
    "#### Encoder\n",
    "\n",
    "Es el problema clásico de utilizar una capa oculta para codificar patrones de 8 valores en una dimensión menor. El objetivo es entrenar un perceptrón 8-3-8 para que aprenda esta codificación en el 100% de los ejemplos.  Es un problema de clasificación.\n",
    "\n",
    "#### Pima-diabetes\n",
    "\n",
    "Contiene resultados de un conjunto de análisis y pruebas en personas que posteriormente desarrollaron o no diabetes. La idea es ver si se puede predecir si una persona va a desarrollar la enfermedad en el futuro.\n",
    "\n",
    "En este caso hay que separar aleatoriamente un 30% de ejemplos para tener una conjunto de test. Nota: se sugiere usar la función shuffle.\n",
    "\n",
    "Cuestiones: ¿Cuál es el porcentaje de acierto estimado en test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptrón multi capa para 3 capas ocultas\n",
    "# lista de neuronas \n",
    "# \n",
    "class MultilayerPro:\n",
    "    def __init__(self, ninput, nhidden, noutput):\n",
    "        self.ninput = ninput\n",
    "        self.nhidden = nhidden\n",
    "        self.noutput = noutput\n",
    "\n",
    "        self.w = []\n",
    "        self.b = []\n",
    "        for a in range(nhidden + 1): \n",
    "            self.w.append(np.random.rand(ninput,nhidden)-0.5)\n",
    "            self.b.append(np.random.rand(nhidden)-0.5)\n",
    "        \n",
    "        self.sx = []\n",
    "        \n",
    "        self.lRMS = [] # contiene la lista de RMSs para pintarlos\n",
    "        self.laccuracy = [] # contiene la lista de accuracy\n",
    "\n",
    "    def sigm (self, neta):\n",
    "        return 1.0 / (1.0 + np.exp(-neta))\n",
    "    \n",
    "    def forward (self, x): # propaga un vector x y devuelve la salida\n",
    "        self.sx = []\n",
    "        \n",
    "        for a in range(self.nhidden):\n",
    "            netax = np.matmul(x,self.w[a]) + self.b[a];\n",
    "            self.sx.append(self.sigm(netax)) # sk = Fs(s(k-1)*Wk+bk)\n",
    "            x = sx[-1]\n",
    "            \n",
    "        return self.sx[-1]\n",
    "    \n",
    "    def update (self, x, d, alpha): # realiza una iteración de entrenamiento\n",
    "        # a implementar\n",
    "        AW = []    # delta pesos   inicia de la capa final y termina en la inicial  F-->I\n",
    "        Ab = []    # delta bias    inicia de la capa final y termina en la inicial  F-->I\n",
    "        delta = [] # Deltas error  inicia de la capa final y termina en la inicial  F-->I\n",
    "        #sx = []    # Salidas inicia en la capa inicial y termina en la final  I-->F\n",
    "        \n",
    "        self.forward(x)\n",
    "        # Retropropagar \n",
    "        # Capa final\n",
    "        # Error de la capa final \n",
    "        delta.append((d-self.sx[-1])*self.sx[-1]*([1]-self.sx[-1])) # Error para la capa final\n",
    "\n",
    "        # Modificar pesos para la capa final\n",
    "        s1tras = self.sx[nhidden-2].reshape(-1,1) #trasponer\n",
    "        \n",
    "        AW.append(alpha * s1tras * delta[0]) # dif pesos\n",
    "        Ab.append(alpha * delta[0]) # dif bias\n",
    "        \n",
    "        \n",
    "        \n",
    "        for a in range(self.nhidden -1): # nhidden -1 ya que están realizados los cálculos para la última capa\n",
    "        # Para la capa nhidden - a\n",
    "        # Error \n",
    "        Wanterior = self.w[nhidden-a].transpose() \n",
    "        fderivada = self.sx[nhidden] * ([1] - self.sx[0])\n",
    "        fderivada = self.sx[0] * ([1] - self.sx[0])\n",
    "        \n",
    "        delta.append(np.matmul(delta[0], Wanterior)*fderivada)\n",
    "        \n",
    "        # Modificar pesos para la primera capa\n",
    "        s0tras = x.reshape(-1,1) #trasponer\n",
    "        AW.append(alpha * s0tras * delta[1]) # dif pesos\n",
    "        Ab.append(alpha * delta[1]) # dif bias\n",
    "        \n",
    "        #actualizar pesos y bias\n",
    "        # Capa 2 \n",
    "        self.w2 = self.w2 + AW[0]\n",
    "        self.b2 = self.b2 + Ab[0]\n",
    "        \n",
    "        # Capa 1 \n",
    "        self.w1 = self.w1 + AW[1]\n",
    "        self.b1 = self.b1 + Ab[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def RMS (self, X, D):\n",
    "        S = self.forward(X)\n",
    "        return np.mean(np.sqrt(np.mean(np.square(S-D),axis=1)))\n",
    "        \n",
    "    def accuracy (self, X, D):\n",
    "        S = self.forward(X)\n",
    "        S = np.round(S)\n",
    "        errors = np.mean(np.abs(D-S))\n",
    "        return 1.0 - errors\n",
    "    \n",
    "    def info (self, X, D):\n",
    "        self.lRMS.append(self.RMS(X,D))\n",
    "        self.laccuracy.append(self.accuracy(X,D))\n",
    "        print('     RMS: %6.5f' % self.lRMS[-1])\n",
    "        print('Accuracy: %6.5f' % self.laccuracy[-1])\n",
    "        \n",
    "    def train (self, X, D, alpha, epochs, trace=0):\n",
    "        self.lRMS = [] # guarda lista de RMSs para pintarlos\n",
    "        self.laccuracy = [] # guarda lista de accuracy\n",
    "\n",
    "        for e in range(1,epochs+1):\n",
    "            for i in range(len(X)):\n",
    "                self.update(X[i],D[i], alpha)\n",
    "            if trace!=0 and e%trace == 0:\n",
    "                print('\\n   Epoch: %d' % e)\n",
    "                self.info(X,D)\n",
    "                \n",
    "def one_hot (d):\n",
    "    num_classes = len(set(d))\n",
    "    rows = d.shape[0]\n",
    "    labels = np.zeros((rows, num_classes), dtype='float32')\n",
    "    labels[np.arange(rows),d.T] = 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xor\n",
    "data = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "labels = np.array([[0.0], [1.0], [1.0], [0.0]])\n",
    "\n",
    "p = MultilayerPro(2,2,1)\n",
    "\n",
    "p.info(data, labels)\n",
    "p.train(data, labels, 1, 5000, 1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
