{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actividad de perceptrón y perceptrón multicapa\n",
    "#### Autor: Francisco Serradilla\n",
    "\n",
    "Tareas:\n",
    "\n",
    "- Escribir el código de propagación y actualización de pesos del perceptrón. [Done]\n",
    "- Escribir el código de propagación y actualización de pesos del perceptrón multicapa para una capa oculta.\n",
    "- Encontrar arquitecturas mínimas para el problema no lineal y el problema de clasificación de orquídeas.\n",
    "- Ampliar el código del perceptrón Multicapa para calcular el error de test a partir de otro conjunto de datos.\n",
    "- Probar entrenamiento y cálculo del error de test con el juego de datos de aprobados.\n",
    "- (hacer al menos dos) Probar con problemas adicionales (circulo, aprobados, fun, morosos). Al final hay una explicación de los conjuntos de datos suministrados.\n",
    "- (opcional) Añadir una segunda capa oculta al perceptrón multacapa y/o un múmero indefinido de capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, ninput, noutput):\n",
    "        self.ninput = ninput\n",
    "        self.noutput = noutput\n",
    "        self.w = np.random.rand(ninput,noutput)-0.5\n",
    "        self.b = np.random.rand(noutput)-0.5\n",
    "        \n",
    "    def forward (self, x): # propaga un vector x y devuelve la salida\n",
    "        # a implementar\n",
    "        #np.matmul() multiplica matrices\n",
    "        neta = np.matmul(x,self.w) + self.b;\n",
    "        return np.piecewise(neta, [neta < 0, neta >= 0], [0, 1]) #funcion escalon\n",
    "    \n",
    "    def update (self, x, d, alpha): # realiza una iteración de entrenamiento\n",
    "        s = self.forward(x) # propaga\n",
    "        etranspose = x.reshape(-1,1) #trasponer el vector (todos sus elementos con -1) a 1 columna\n",
    "        AW = alpha*etranspose*(d-s)\n",
    "        self.w = self.w + AW\n",
    "        \n",
    "    def RMS (self, X, D):\n",
    "        S = self.forward(X)\n",
    "        return np.mean(np.sqrt(np.mean(np.square(S-D),axis=1)))\n",
    "        \n",
    "    def accuracy (self, X, D):\n",
    "        S = self.forward(X)\n",
    "        errors = np.mean(np.abs(D-S))\n",
    "        return 1.0 - errors\n",
    "    \n",
    "    def info (self, X, D):\n",
    "        print('     RMS: %6.5f' % self.RMS(X,D))\n",
    "        print('Accuracy: %6.5f' % self.accuracy(X,D))\n",
    "        \n",
    "    def train (self, X, D, alpha, epochs, trace=0):\n",
    "        for e in range(1,epochs+1):\n",
    "            for i in range(len(X)):\n",
    "                self.update(X[i],D[i], alpha)\n",
    "            if trace!=0 and e%trace == 0:\n",
    "                print('\\n   Epoch: %d' % e)\n",
    "                self.info(X,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     RMS: 0.25000\n",
      "Accuracy: 0.75000\n",
      "\n",
      "   Epoch: 10\n",
      "     RMS: 0.25000\n",
      "Accuracy: 0.75000\n",
      "\n",
      "   Epoch: 20\n",
      "     RMS: 0.00000\n",
      "Accuracy: 1.00000\n",
      "\n",
      "   Epoch: 30\n",
      "     RMS: 0.00000\n",
      "Accuracy: 1.00000\n",
      "\n",
      "   Epoch: 40\n",
      "     RMS: 0.00000\n",
      "Accuracy: 1.00000\n",
      "\n",
      "   Epoch: 50\n",
      "     RMS: 0.00000\n",
      "Accuracy: 1.00000\n"
     ]
    }
   ],
   "source": [
    "# entrena para la OR\n",
    "\n",
    "p = Perceptron(2,1)\n",
    "\n",
    "# or\n",
    "data = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "labels = np.array([[0.0], [1.0], [1.0], [1.0]])\n",
    "\n",
    "p.info(data, labels)\n",
    "p.train(data, labels, 0.01, 50, 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptrón multi capa para una capa oculta \n",
    "class Multilayer:\n",
    "    def __init__(self, ninput, nhidden, noutput):\n",
    "        self.ninput = ninput\n",
    "        self.nhidden = nhidden\n",
    "        self.noutput = noutput\n",
    "\n",
    "        self.w1 = np.random.rand(ninput,nhidden)-0.5\n",
    "        self.b1 = np.random.rand(nhidden)-0.5\n",
    "        self.w2 = np.random.rand(nhidden,noutput)-0.5\n",
    "        self.b2 = np.random.rand(noutput)-0.5\n",
    "        \n",
    "        self.lRMS = [] # contiene la lista de RMSs para pintarlos\n",
    "        self.laccuracy = [] # contiene la lista de accuracy\n",
    "\n",
    "    def sigm (self, neta):\n",
    "        return 1.0 / (1.0 + np.exp(-neta))\n",
    "    \n",
    "    def forward (self, x): # propaga un vector x y devuelve la salida\n",
    "        netax = np.matmul(x,self.w1) + self.b1;\n",
    "        sx = self.sigm(netax) # sk = Fs(s(k-1)*Wk+bk)\n",
    "        return sx\n",
    "    \n",
    "    def update (self, x, d, alpha): # realiza una iteración de entrenamiento\n",
    "        # a implementar\n",
    "        AW = []    # delta pesos   inicia de la capa final y termina en la inicial  F-->I\n",
    "        Ab = []    # delta bias    inicia de la capa final y termina en la inicial  F-->I\n",
    "        delta = [] # Deltas error  inicia de la capa final y termina en la inicial  F-->I\n",
    "        sx = []    # Salidas inicia en la capa inicial y termina en la final  I-->F\n",
    "        \n",
    "        # Propagación \n",
    "        # Capa 1\n",
    "        #sx.append(self.forward(x))     # Salida para la propagación de la capa 1\n",
    "        netax = np.matmul(x,self.w1) + self.b1;\n",
    "        sx.append(self.sigm(netax)) # sk = Fs(s(k-1)*Wk+bk)\n",
    "        \n",
    "        # Capa 2\n",
    "        #sx.append(self.forward(sx[0])) # Salida para la propagación de la capa 2\n",
    "        netax = np.matmul(sx[0],self.w2) + self.b2;\n",
    "        sx.append(self.sigm(netax)) # sk = Fs(s(k-1)*Wk+bk)\n",
    "        \n",
    "        # Retropropagar \n",
    "        # Capa final (capa 2)\n",
    "        # Error de la capa final \n",
    "        delta.append((d-sx[1])*sx[1]*([1]-sx[1])) # Error para la capa final (capa 2)\n",
    "        \n",
    "        # Modificar pesos para la capa final\n",
    "        s1tras = sx[0].reshape(-1,1) #trasponer\n",
    "        AW.append(alpha * s1tras * delta[0]) # dif pesos\n",
    "        Ab.append(alpha * delta[0]) # dif bias\n",
    "        \n",
    "        self.w2 = self.w2 + AW[0]\n",
    "        self.b2 = self.b2 + Ab[0]\n",
    "        \n",
    "        \n",
    "        # Primera capa (capa 1)\n",
    "        # Error de la primera capa (capa 1)\n",
    "        W2tras = self.w2.transpose() ## creo que este era el error \n",
    "        '''\n",
    "        print(\"delta[0]\")\n",
    "        print(delta[0])\n",
    "        \n",
    "        print(\"w2\")\n",
    "        print(self.w2)\n",
    "        print(\"w2 tras\")\n",
    "        print(W2tras)\n",
    "        '''\n",
    "        fderivada = sx[0] * ([1] - sx[0])\n",
    "        delta.append(np.matmul(delta[0], W2tras)*fderivada)\n",
    "        \n",
    "        # Modificar pesos para la primera capa\n",
    "        s0tras = x.reshape(-1,1) #trasponer\n",
    "        AW.append(alpha * s0tras * delta[1]) # dif pesos\n",
    "        Ab.append(alpha * delta[1]) # dif bias\n",
    "        \n",
    "        #actualizar pesos y bias\n",
    "        self.w1 = self.w1 + AW[1]\n",
    "        self.b1 = self.b1 + Ab[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def RMS (self, X, D):\n",
    "        S = self.forward(X)\n",
    "        return np.mean(np.sqrt(np.mean(np.square(S-D),axis=1)))\n",
    "        \n",
    "    def accuracy (self, X, D):\n",
    "        S = self.forward(X)\n",
    "        S = np.round(S)\n",
    "        errors = np.mean(np.abs(D-S))\n",
    "        return 1.0 - errors\n",
    "    \n",
    "    def info (self, X, D):\n",
    "        self.lRMS.append(self.RMS(X,D))\n",
    "        self.laccuracy.append(self.accuracy(X,D))\n",
    "        print('     RMS: %6.5f' % self.lRMS[-1])\n",
    "        print('Accuracy: %6.5f' % self.laccuracy[-1])\n",
    "        \n",
    "    def train (self, X, D, alpha, epochs, trace=0):\n",
    "        self.lRMS = [] # guarda lista de RMSs para pintarlos\n",
    "        self.laccuracy = [] # guarda lista de accuracy\n",
    "\n",
    "        for e in range(1,epochs+1):\n",
    "            for i in range(len(X)):\n",
    "                self.update(X[i],D[i], alpha)\n",
    "            if trace!=0 and e%trace == 0:\n",
    "                print('\\n   Epoch: %d' % e)\n",
    "                self.info(X,D)\n",
    "                \n",
    "def one_hot (d):\n",
    "    num_classes = len(set(d))\n",
    "    rows = d.shape[0]\n",
    "    labels = np.zeros((rows, num_classes), dtype='float32')\n",
    "    labels[np.arange(rows),d.T] = 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     RMS: 0.50426\n",
      "Accuracy: 0.50000\n",
      "\n",
      "   Epoch: 1000\n",
      "     RMS: 0.59150\n",
      "Accuracy: 0.50000\n",
      "\n",
      "   Epoch: 2000\n",
      "     RMS: 0.58091\n",
      "Accuracy: 0.50000\n",
      "\n",
      "   Epoch: 3000\n",
      "     RMS: 0.57619\n",
      "Accuracy: 0.50000\n",
      "\n",
      "   Epoch: 4000\n",
      "     RMS: 0.57363\n",
      "Accuracy: 0.50000\n",
      "\n",
      "   Epoch: 5000\n",
      "     RMS: 0.57200\n",
      "Accuracy: 0.50000\n"
     ]
    }
   ],
   "source": [
    "# xor\n",
    "data = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "labels = np.array([[0.0], [1.0], [1.0], [0.0]])\n",
    "\n",
    "p = Multilayer(2,2,1)\n",
    "\n",
    "p.info(data, labels)\n",
    "p.train(data, labels, 1, 5000, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL: Perceptrón multicapa para l capas ocultas \n",
    "class Multilayer:\n",
    "    def __init__(self, ninput, nhidden, noutput):\n",
    "        self.ninput = ninput\n",
    "        self.nhidden = nhidden\n",
    "        self.noutput = noutput\n",
    "\n",
    "        self.w1 = np.random.rand(ninput,nhidden)-0.5\n",
    "        self.b1 = np.random.rand(nhidden)-0.5\n",
    "        self.w2 = np.random.rand(nhidden,noutput)-0.5\n",
    "        self.b2 = np.random.rand(noutput)-0.5\n",
    "        \n",
    "        self.lRMS = [] # contiene la lista de RMSs para pintarlos\n",
    "        self.laccuracy = [] # contiene la lista de accuracy\n",
    "\n",
    "    def sigm (self, neta):\n",
    "        return 1.0 / (1.0 + np.exp(-neta))\n",
    "    \n",
    "    # propagacion \n",
    "    # Pasos \n",
    "    # 1. Propagar hacia adelante para todas las capas \n",
    "    # 2. Una vez que se llegó a la última capa, retropropagar\n",
    "    def forward (self, x): # propaga un vector x y devuelve la salida\n",
    "        # x siempre debe ser s(k-1) \n",
    "        # Fs = función sigmoidal\n",
    "        # s0 = x #entrada\n",
    "        # s1 = Fs(s0*W1+b1)\n",
    "        # s2 = Fs(s1*W2+b2)\n",
    "        # sk = Fs(s(k-1)*Wk+bk)\n",
    "        # a implementar\n",
    "        netax = np.matmul(x,self.w1) + self.b1;\n",
    "        sx = self.sigm(netax) # sk = Fs(s(k-1)*Wk+bk)\n",
    "        return sx\n",
    "    \n",
    "    def update (self, x, d, alpha): # realiza una iteración de entrenamiento\n",
    "        # a implementar\n",
    "        # delta(k) = (d - s(k))*s(k)*([1]-s(k))    delta\n",
    "        # AW(k) = alpha*s(k-1)t*delta(k)           peso\n",
    "        # Ab(k) = alpha*delta(k)                   bias\n",
    "        \n",
    "        sk = forward(x)\n",
    "        deltak = (d -)\n",
    "        \n",
    "        \n",
    "        AW = []      # pesos\n",
    "        Ab = []      # bias\n",
    "        delta = []   # deltas\n",
    "        salidas = [] # salidas \n",
    "        \n",
    "        \n",
    "        \n",
    "        s = self.forward(x)\n",
    "        s1tras = s[0].reshape(-1,1) #trasponer\n",
    "\n",
    "        delta.append((d-s[1])*s[1]*([1]-s[1])) #error de la capa final (2)\n",
    "        AW.append(alpha * s1tras * delta[0]) #actualizacion de pesos capa final\n",
    "        Ab.append(alpha * delta[0]) #bias\n",
    "        \n",
    "        #capa oculta (1)\n",
    "        AWtras = AW[0].reshape(-1,2)\n",
    "        stras = s[1].reshape(-1,1)\n",
    "        fs = s[0] * ([1] - s[0])\n",
    "        delta.append(np.matmul(delta[0],AWtras)*fs)\n",
    "        AW.append(alpha*stras*delta[1])\n",
    "        Ab.append(alpha*delta[1])\n",
    "        \n",
    "        #actualizar pesos y bias\n",
    "        self.w1 = self.w1 + AW[0]\n",
    "        self.b1 = self.b1 + Ab[0]\n",
    "        \n",
    "        self.w2 = self.w2 + AW[1]\n",
    "        self.b2 = self.b2 + Ab[1]\n",
    "        \n",
    "        \n",
    "    \n",
    "    def RMS (self, X, D):\n",
    "        S = self.forward(X)\n",
    "        return np.mean(np.sqrt(np.mean(np.square(S-D),axis=1)))\n",
    "        \n",
    "    def accuracy (self, X, D):\n",
    "        S = self.forward(X)\n",
    "        S = np.round(S)\n",
    "        errors = np.mean(np.abs(D-S))\n",
    "        return 1.0 - errors\n",
    "    \n",
    "    def info (self, X, D):\n",
    "        self.lRMS.append(self.RMS(X,D))\n",
    "        self.laccuracy.append(self.accuracy(X,D))\n",
    "        print('     RMS: %6.5f' % self.lRMS[-1])\n",
    "        print('Accuracy: %6.5f' % self.laccuracy[-1])\n",
    "        \n",
    "    def train (self, X, D, alpha, epochs, trace=0):\n",
    "        self.lRMS = [] # guarda lista de RMSs para pintarlos\n",
    "        self.laccuracy = [] # guarda lista de accuracy\n",
    "\n",
    "        for e in range(1,epochs+1):\n",
    "            for i in range(len(X)):\n",
    "                self.update(X[i],D[i], alpha)\n",
    "            if trace!=0 and e%trace == 0:\n",
    "                print('\\n   Epoch: %d' % e)\n",
    "                self.info(X,D)\n",
    "                \n",
    "def one_hot (d):\n",
    "    num_classes = len(set(d))\n",
    "    rows = d.shape[0]\n",
    "    labels = np.zeros((rows, num_classes), dtype='float32')\n",
    "    labels[np.arange(rows),d.T] = 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# example data from two classes; 2D normal distributions\n",
    "num = 100\n",
    "x0 = np.random.multivariate_normal([2,2], np.array([[1,0],[0,1]]),num)\n",
    "d0 = np.repeat(0, num)\n",
    "x1 = np.random.multivariate_normal([-2,-2], np.array([[1,0],[0,1]]),num)\n",
    "d1 = np.repeat(1, num)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlim(-6,6)\n",
    "plt.ylim(-6,6)\n",
    "plt.plot(x0[:,0],x0[:,1],'o')\n",
    "plt.plot(x1[:,0],x1[:,1],'o')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "X = np.vstack((x0,x1))\n",
    "d = np.hstack((d0,d1))\n",
    "d.shape = (200,1) # convierte el vector en un array\n",
    "\n",
    "p = Perceptron(2,1)\n",
    "\n",
    "p.train(X, d, 0.01, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# regiones no lineales\n",
    "\n",
    "X = np.loadtxt('samples\\data_3classes_nonlinear_2D.txt')\n",
    "\n",
    "d = X[:,-1].astype('int')\n",
    "X = X[:,:-1]\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.plot(X[d==0,0],X[d==0,1], 'ro')\n",
    "plt.plot(X[d==1,0],X[d==1,1], 'go')\n",
    "plt.plot(X[d==2,0],X[d==2,1], 'bo')\n",
    "plt.show()\n",
    "\n",
    "no = len(set(d))\n",
    "ni = X.shape[1]\n",
    "\n",
    "d = one_hot(d)\n",
    "\n",
    "p = Multilayer(ni,15,no)\n",
    "\n",
    "# encontrar arquitectura mínima que aprende este problema, para data_2classes_nonlinear_2D.txt y para data_3classes_nonlinear_2D.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orquideas\n",
    "\n",
    "X = np.loadtxt('samples\\iris.csv', dtype = 'float64', usecols = [0,1,2,3])\n",
    "L = np.loadtxt('samples\\iris.csv', dtype = str, usecols = [4]) \n",
    "\n",
    "# convierte la salida a enteros\n",
    "d = []\n",
    "options = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "for e in L:\n",
    "    d.append(options.index(e))\n",
    "\n",
    "d = np.array(d)\n",
    "X = np.array(X)\n",
    "\n",
    "d = one_hot(d)\n",
    "\n",
    "ni = X.shape[1]\n",
    "no = len(options)\n",
    "\n",
    "p = Multilayer(ni,40,no)\n",
    "\n",
    "# encontrar arquitectura mínima que aprende este problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicación de los archivos de datos suministrados\n",
    "\n",
    "#### Aprobados\n",
    "\n",
    "Contiene 3 entradas, correspondiente a la nota en 3 ejercicios, y 1 salida, que indica si el alumno aprobó o no. Se trataría de predecir si un alumno va a aprobar a partir de sus notas. Es un problema de clasificación.\n",
    "\n",
    "Cuestiones: ¿Es un problema lineal? ¿Puede aprenderla una red de neuronas?\n",
    "\n",
    "#### Fun\n",
    "\n",
    "Contiene 1 entrada y 1 salida, que son la *x* y la *y* de una función desconocida. Es un problema de ajuste o regresión.\n",
    "\n",
    "Cuestiones: ¿Es una función lineal? ¿Puede aprenderla una red de neuronas? ¿Puede decirnos la red qué función es?\n",
    "\n",
    "#### Morosos\n",
    "\n",
    "Contiene datos de morosidad de un banco. La idea es predecir si un nuevo cliente va a devolver un prestamo o no y utilizar esta predicción para concederle o denegarle el préstamo. Es un problema de clasificación.\n",
    "\n",
    "Tiene 9 entradas y 1 salida.\n",
    "\n",
    "Cuestiones: ¿Es una función lineal? ¿Cuál es el porcentaje de acierto estimado en test?\n",
    "\n",
    "#### Quinielas\n",
    "\n",
    "Contiene datos de quinielas deportivas. Tiene 60 entradas y 3 salidas (1, X, 2). Es un problema de clasificación.\n",
    "\n",
    "Cuestiones: ¿Cuál es el porcentaje de acierto estimado en test?\n",
    "\n",
    "#### Sensores\n",
    "\n",
    "Contiene datos de sensores y velocidades medias en la M-40. La idea es ver si se puede predecir la velocidad media en un punto que no tiene sensor a partir de las lecturas de los sensores en otros puntos. Es un problema de ajuste o regresión.\n",
    "\n",
    "Cuestiones: ¿Cuál es el porcentaje de acierto estimado en test?\n",
    "\n",
    "#### Circulo\n",
    "\n",
    "Es un problema de clasificación con 3 regiones concéntricas. No tiene conjunto de test, el objetivo es encontrar la red mínima que pueda clasificar correctamente todos los ejemplos.\n",
    "\n",
    "#### Encoder\n",
    "\n",
    "Es el problema clásico de utilizar una capa oculta para codificar patrones de 8 valores en una dimensión menor. El objetivo es entrenar un perceptrón 8-3-8 para que aprenda esta codificación en el 100% de los ejemplos.  Es un problema de clasificación.\n",
    "\n",
    "#### Pima-diabetes\n",
    "\n",
    "Contiene resultados de un conjunto de análisis y pruebas en personas que posteriormente desarrollaron o no diabetes. La idea es ver si se puede predecir si una persona va a desarrollar la enfermedad en el futuro.\n",
    "\n",
    "En este caso hay que separar aleatoriamente un 30% de ejemplos para tener una conjunto de test. Nota: se sugiere usar la función shuffle.\n",
    "\n",
    "Cuestiones: ¿Cuál es el porcentaje de acierto estimado en test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
